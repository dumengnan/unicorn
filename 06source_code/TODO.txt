1、安装并学习airflow     --okay
3、kafka 写数据到ES      --okay
4、kafka 写数据到mysql   --okay
4、安装buildbot 做每日构造
5、spark-streaming 接入kafka数据 实时分析统计 最终结果入hbase 
6、使用spring cloud 框架 写上层分析应用接口 
7、简单界面展示
8、fastText 应用  用于文本分类 对用户发表的内容进行训练分类
9、修改爬虫程序 支持图片和视频内容的下载 
10、DeepVideoAnalysis 应用  用于检索图片和视频中的内容



要写一个unicorn-producer  同时支持avro 和 txt 数据格式的发送kafka     --okay   (用nifi 实现)
如果要生成avro的数据格式需要传入schema 文件进行解析                   --okay   (用nifi 实现)



python 安装环境 几个版本要装统一 否则会有问题                        --okay 





STUDY：
1、awk 在中间位置添加列的方法 
    awk -v FS='\t' -v OFS='\t' '{$11=$11"\t""twitter"} 1' a.txt
